{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digits recognizer using convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here a dataset from training kaggle competition is used. This is a MNIST dataset with hand written digits. Actually data could be very well classified even using such algorithms as k Nearest Neighbours. So the aim of this work is get familiar with keras library and convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.utils.np_utils import to_categorical \n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, data \n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 785) (28000, 784)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "print(train.shape, test.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little of data preprocessing is needed here. There are no missing values, so all we have to do is to scale our features (MinMaxScaler could be used also, but to divide by 255 is simplier), input arrays have to be reshaped, and we have to transform vector of classes to a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "X = train.iloc[:,1:].values / 255\n",
    "X_test = test.values / 255\n",
    "y = train['label'].values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state = 147, stratify = y)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "\n",
    "y_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important step: we build a convolutional neural network. The structure of CNN is the following: \n",
    "\n",
    "* Convolutional layer with 32 filters, kernel window 3x3 and ReLU as activation function\n",
    "* Pooling layer with pooling window 2x2\n",
    "* Dropout regularization, dropping 25% \n",
    "* Convolutional layer with 64 filters, kernel window 3x3 and ReLU as activation function\n",
    "* Pooling layer with pooling window 2x2\n",
    "* Dropout regularization, dropping 25%\n",
    "* Flatten layer\n",
    "* Dense layer with 256 output nodes and ReLU as activation function\n",
    "* Dropout regularization, dropping 25%\n",
    "* Dense layer (the last one) with 10 output nodes and softmax as activation function\n",
    "\n",
    "Finally, we compile CNN using Adam as gradient descent optimizer, categorical crossentropy as loss function and accuracy as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:9: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=256)`\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=10)`\n"
     ]
    }
   ],
   "source": [
    "#neural network structure\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (28, 28, 1), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Conv2D(64, (3, 3), activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Flatten())\n",
    "classifier.add(Dense(output_dim = 256, activation = 'relu'))\n",
    "classifier.add(Dropout(0.25))\n",
    "classifier.add(Dense(output_dim = 10, activation = 'softmax'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We fit CNN using batch gradient descent with batch size 64, we pass through all training data 28 times and we use 10% of our data as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 34020 samples, validate on 3780 samples\n",
      "Epoch 1/28\n",
      "34020/34020 [==============================] - 105s - loss: 0.2734 - acc: 0.9132 - val_loss: 0.0775 - val_acc: 0.9783\n",
      "Epoch 2/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0849 - acc: 0.9730 - val_loss: 0.0690 - val_acc: 0.9799\n",
      "Epoch 3/28\n",
      "34020/34020 [==============================] - 106s - loss: 0.0638 - acc: 0.9797 - val_loss: 0.0460 - val_acc: 0.9868\n",
      "Epoch 4/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0480 - acc: 0.9850 - val_loss: 0.0506 - val_acc: 0.9841\n",
      "Epoch 5/28\n",
      "34020/34020 [==============================] - 96s - loss: 0.0413 - acc: 0.9865 - val_loss: 0.0408 - val_acc: 0.9881\n",
      "Epoch 6/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0387 - acc: 0.9872 - val_loss: 0.0292 - val_acc: 0.9913\n",
      "Epoch 7/28\n",
      "34020/34020 [==============================] - 96s - loss: 0.0319 - acc: 0.9897 - val_loss: 0.0298 - val_acc: 0.9907\n",
      "Epoch 8/28\n",
      "34020/34020 [==============================] - 93s - loss: 0.0283 - acc: 0.9909 - val_loss: 0.0410 - val_acc: 0.9884\n",
      "Epoch 9/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0264 - acc: 0.9910 - val_loss: 0.0296 - val_acc: 0.9894\n",
      "Epoch 10/28\n",
      "34020/34020 [==============================] - 98s - loss: 0.0255 - acc: 0.9923 - val_loss: 0.0288 - val_acc: 0.9907\n",
      "Epoch 11/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0222 - acc: 0.9928 - val_loss: 0.0344 - val_acc: 0.9899\n",
      "Epoch 12/28\n",
      "34020/34020 [==============================] - 106s - loss: 0.0178 - acc: 0.9942 - val_loss: 0.0289 - val_acc: 0.9907\n",
      "Epoch 13/28\n",
      "34020/34020 [==============================] - 119s - loss: 0.0200 - acc: 0.9934 - val_loss: 0.0301 - val_acc: 0.9902\n",
      "Epoch 14/28\n",
      "34020/34020 [==============================] - 105s - loss: 0.0156 - acc: 0.9949 - val_loss: 0.0271 - val_acc: 0.9905\n",
      "Epoch 15/28\n",
      "34020/34020 [==============================] - 95s - loss: 0.0166 - acc: 0.9942 - val_loss: 0.0382 - val_acc: 0.9889\n",
      "Epoch 16/28\n",
      "34020/34020 [==============================] - 116s - loss: 0.0166 - acc: 0.9942 - val_loss: 0.0324 - val_acc: 0.9913\n",
      "Epoch 17/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0171 - acc: 0.9949 - val_loss: 0.0391 - val_acc: 0.9881\n",
      "Epoch 18/28\n",
      "34020/34020 [==============================] - 123s - loss: 0.0116 - acc: 0.9960 - val_loss: 0.0398 - val_acc: 0.9905\n",
      "Epoch 19/28\n",
      "34020/34020 [==============================] - 110s - loss: 0.0138 - acc: 0.9957 - val_loss: 0.0352 - val_acc: 0.9902\n",
      "Epoch 20/28\n",
      "34020/34020 [==============================] - 92s - loss: 0.0138 - acc: 0.9954 - val_loss: 0.0431 - val_acc: 0.9897\n",
      "Epoch 21/28\n",
      "34020/34020 [==============================] - 96s - loss: 0.0129 - acc: 0.9959 - val_loss: 0.0438 - val_acc: 0.9913\n",
      "Epoch 22/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0120 - acc: 0.9960 - val_loss: 0.0422 - val_acc: 0.9907\n",
      "Epoch 23/28\n",
      "34020/34020 [==============================] - 102s - loss: 0.0118 - acc: 0.9958 - val_loss: 0.0459 - val_acc: 0.9902\n",
      "Epoch 24/28\n",
      "34020/34020 [==============================] - 104s - loss: 0.0099 - acc: 0.9967 - val_loss: 0.0411 - val_acc: 0.9910\n",
      "Epoch 25/28\n",
      "34020/34020 [==============================] - 104s - loss: 0.0103 - acc: 0.9969 - val_loss: 0.0356 - val_acc: 0.9907\n",
      "Epoch 26/28\n",
      "34020/34020 [==============================] - 101s - loss: 0.0119 - acc: 0.9962 - val_loss: 0.0325 - val_acc: 0.9913\n",
      "Epoch 27/28\n",
      "34020/34020 [==============================] - 99s - loss: 0.0123 - acc: 0.9963 - val_loss: 0.0335 - val_acc: 0.9907\n",
      "Epoch 28/28\n",
      "34020/34020 [==============================] - 102s - loss: 0.0095 - acc: 0.9970 - val_loss: 0.0353 - val_acc: 0.9907\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x121e03668>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fitting\n",
    "classifier.fit(X_train, y_train, epochs = 28, batch_size = 64, validation_split = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.993333333333 [[413   0   0   0   0   0   0   0   0   0]\n",
      " [  0 467   0   0   1   0   0   0   0   0]\n",
      " [  0   1 414   1   0   0   0   2   0   0]\n",
      " [  0   0   3 430   0   1   0   0   0   1]\n",
      " [  0   0   0   0 403   0   0   0   0   4]\n",
      " [  1   0   0   0   0 374   3   0   1   1]\n",
      " [  0   0   0   0   1   0 413   0   0   0]\n",
      " [  0   0   1   0   0   0   0 438   0   1]\n",
      " [  0   0   0   0   0   0   1   0 403   2]\n",
      " [  0   0   0   0   1   0   0   0   1 417]]\n"
     ]
    }
   ],
   "source": [
    "#predicting validation set\n",
    "y_val_pred = classifier.predict(X_val)\n",
    "y_val_pred = np.argmax(y_val_pred, axis = 1)\n",
    "print(accuracy_score(y_val, y_val_pred), confusion_matrix(y_val, y_val_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis = 1)\n",
    "prediction = pd.concat([pd.Series(range(1, X_test.shape[0] + 1), name = 'ImageId'), pd.Series(y_pred, name = 'Label')], axis = 1)\n",
    "prediction.to_csv('prediction.csv', sep = ',', header = True, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got 0.997 accuracy on training set, 0.993 on validation set and 0.991 on test set. Good result, which belongs to top400 on kaggle (actually higher, because there are many false submissions, nevertheless model could be improved adding new layers and tuning hyperparameters.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
